{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SSL_MasterFile_Tomato.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuGew0mBo6Nm"
      },
      "source": [
        "# Master file Tomato - Testing the SSL Approach\n",
        "\n",
        "Our team attempted a self-supervised algorithm for the tomato and potato models in attempt to increase model generalizability. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "659nNMaacXjN"
      },
      "source": [
        "# 1. Load the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6knIUbecKhk",
        "outputId": "d32c003e-3a31-4eb6-aabc-959ad92fc225"
      },
      "source": [
        "# download the Kaggle dataset instructions here:\n",
        "# https://medium.com/analytics-vidhya/how-to-fetch-kaggle-datasets-into-google-colab-ea682569851a\n",
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# configure path to Kaggle json file \n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "# /content/gdrive/My Drive/Kaggle is the path where kaggle.json is present in the Google Drive\n",
        "\n",
        "#changing the working directory\n",
        "%cd /content/gdrive/My Drive/Kaggle\n",
        "#Check the present working directory using pwd command\n",
        "\n",
        "#download kaggle dataset\n",
        "# comment out so i dont re-download everytime\n",
        "# !kaggle datasets download -d emmarex/plantdisease\n",
        "\n",
        "#unzip the Plan Village Dataset\n",
        "#unzipping the zip files and deleting the zip files\n",
        "# !unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/.shortcut-targets-by-id/1AE_ah6OZ6tuGxdM5Y8ousz-lKzgRa6TZ/Kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk9sV5g4crD8"
      },
      "source": [
        "# 2. Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KQUs9fMcuE0"
      },
      "source": [
        "import random as random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n",
        "from scipy.ndimage import rotate\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Input\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from  matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.regularizers import l2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL62V98xXjNT"
      },
      "source": [
        "# 3. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnJ1Qwf_Xi73",
        "outputId": "e2e699eb-c210-49fc-983f-af7cf55f24c0"
      },
      "source": [
        "print(os.getcwd())\n",
        "data_dir=r'/content/gdrive/My Drive/Kaggle/PlantVillage_Sorted/'\n",
        "general_data_dir=r'/content/gdrive/My Drive/General_Validation_Datasets/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1AE_ah6OZ6tuGxdM5Y8ousz-lKzgRa6TZ/Kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LZ1yMDvQli6"
      },
      "source": [
        "### Tomato Image Data Generator Classes\n",
        "\n",
        "Only using 4 tomato classes here:\n",
        "\n",
        "* Tomato_healthy\n",
        "* Tomato_Leaf_Mold\n",
        "* Tomato__Target_Spot\n",
        "* Tomato__Tomato_mosaic_virus\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoO4nJmpXV2S",
        "outputId": "a79515f4-1b87-4012-c58c-f8cdf57f563a"
      },
      "source": [
        "seed = 909 # (IMPORTANT) to input image and corresponding target with same augmentation parameter.\n",
        "image_size = (250,250)\n",
        "batch = 32\n",
        "# the image hierarchy is important\n",
        "# see: https://stackoverflow.com/questions/49535561/imagedatagenerator-on-a-folder\n",
        "\n",
        "# kaggle --->PlantVillage folder\n",
        "#               |\n",
        "#               Development folder\n",
        "#                   split the total amount of images into 80% development, \n",
        "#                   and this will be further split by dev_params into tran and val generators (in code)\n",
        "#                         |___> all 9 classes exist in this folder with 80% of the total photos\n",
        "#               |\n",
        "#               |\n",
        "#               Test folder\n",
        "#                   split the total amount of images into 20% test\n",
        "#                         |___> all 9 classes exist in this folder with 20% of the total photos\n",
        "\n",
        "# General_Validation_Datasets\n",
        "#               | Contains all classes with data found from general sources\n",
        "\n",
        "# CREATE THE TRAIN/VAL GENERATORS HERE\n",
        "# notice that i split the gen_params into 10% val 90% train \n",
        "dev_params = { \"validation_split\":0.1, \"rescale\":1.0/255,\"featurewise_center\":False,\"samplewise_center\":False,\"featurewise_std_normalization\":False,\\\n",
        "              \"samplewise_std_normalization\":False,\"zca_whitening\":False,\"rotation_range\":20,\"width_shift_range\":0.1,\"height_shift_range\":0.1,\\\n",
        "              \"shear_range\":0.2, \"zoom_range\":0.1,\"horizontal_flip\":True,\"fill_mode\":'nearest',\\\n",
        "               \"cval\": 0}\n",
        "\n",
        "train_image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**dev_params) \n",
        "val_image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**dev_params) \n",
        "\n",
        "# use classes tag to only specify a certain class \n",
        "train_generator = train_image_datagen.flow_from_directory(data_dir+'development', subset = 'training', classes = [ 'Tomato_healthy', 'Tomato_Leaf_Mold', 'Tomato__Target_Spot', 'Tomato__Tomato_mosaic_virus'],\n",
        "                                                     batch_size = batch,seed=seed, target_size=image_size,color_mode='rgb',shuffle = True)\n",
        "val_generator = val_image_datagen.flow_from_directory(data_dir+'development', subset = 'validation', classes = [ 'Tomato_healthy', 'Tomato_Leaf_Mold', 'Tomato__Target_Spot', 'Tomato__Tomato_mosaic_virus'],\n",
        "                                                     batch_size = batch,seed=seed, target_size=image_size,color_mode='rgb',shuffle = True)\n",
        "\n",
        "# CREATE THE TEST GENERATOR HERE\n",
        "test_dir = data_dir+'test' # This is the test folder!!\n",
        "test_params = {\"rescale\":1.0/255,\"featurewise_center\":False,\"samplewise_center\":False,\"featurewise_std_normalization\":False,\\\n",
        "              \"samplewise_std_normalization\":False,\"zca_whitening\":False,\"rotation_range\":20,\"width_shift_range\":0.1,\"height_shift_range\":0.1,\\\n",
        "              \"shear_range\":0.2, \"zoom_range\":0.1,\"horizontal_flip\":True,\"fill_mode\":'nearest',\\\n",
        "               \"cval\": 0}\n",
        "test_image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**test_params) \n",
        "# use classes tag to only specify a certain class \n",
        "test_generator = train_image_datagen.flow_from_directory(test_dir, classes = [ 'Tomato_healthy', 'Tomato_Leaf_Mold', 'Tomato__Target_Spot', 'Tomato__Tomato_mosaic_virus'],\n",
        "                                                         batch_size = batch,seed=seed, target_size=image_size,color_mode='rgb',shuffle = True)\n",
        "\n",
        "\n",
        "# CREATE THE GENERAL TEST GENERATOR HERE (testing dataset outside of PlantVillage)\n",
        "test = 'ON' # turning this test case on/off\n",
        "if test is 'ON':\n",
        "  general_test_params = {\"rescale\":1.0/255,\"featurewise_center\":False,\"samplewise_center\":False,\"featurewise_std_normalization\":False,\\\n",
        "                \"samplewise_std_normalization\":False,\"zca_whitening\":False,\"rotation_range\":10,\"width_shift_range\":0.1,\"height_shift_range\":0.1,\\\n",
        "                \"shear_range\":0.2, \"zoom_range\":0.1,\"horizontal_flip\":True,\"fill_mode\":'nearest',\\\n",
        "                \"cval\": 0}\n",
        "\n",
        "  general_test_image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**test_params) \n",
        "\n",
        "  # use classes tag to only specify a certain class \n",
        "  general_test_generator = train_image_datagen.flow_from_directory(general_data_dir, classes = ['Tomato_healthy', 'Tomato_Leaf_Mold', 'Tomato__Target_Spot', 'Tomato__Tomato_mosaic_virus'],\n",
        "                                                          batch_size = batch,seed=seed, target_size=image_size,color_mode='rgb',shuffle = True)\n",
        "else:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3110 images belonging to 4 classes.\n",
            "Found 344 images belonging to 4 classes.\n",
            "Found 866 images belonging to 4 classes.\n",
            "Found 16 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr3yiJfbR2Lc"
      },
      "source": [
        "# 4. SSL Pre-Text\n",
        "\n",
        "Defining and training a model on a pretext task (i.e., image rotation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rhuOU3dYm2g"
      },
      "source": [
        "## Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c28AtzURzzl"
      },
      "source": [
        "def my_model_pretext(ishape = (250,250,3), k = 4, lr = 1e-4):\n",
        "    model_input = tf.keras.layers.Input(shape = ishape)\n",
        "    l1 = tf.keras.layers.Conv2D(48, (3,3), padding='same', activation='relu')(model_input)\n",
        "    l2 = tf.keras.layers.Conv2D(48, (3,3), padding='same', activation='relu')(l1)\n",
        "    l2_drop = tf.keras.layers.Dropout(0.25)(l2)\n",
        "    l3 = tf.keras.layers.MaxPool2D((2,2))(l2_drop)\n",
        "    l4 = tf.keras.layers.Conv2D(96, (3,3), padding='same', activation='relu')(l3)\n",
        "    l5 = tf.keras.layers.Conv2D(96, (3,3), padding='same', activation='relu')(l4)\n",
        "    l5_drop = tf.keras.layers.Dropout(0.25)(l5)\n",
        "    flat = tf.keras.layers.Flatten()(l5_drop)\n",
        "    model_pretext = tf.keras.models.Model(inputs = model_input, outputs = flat)\n",
        "    out = tf.keras.layers.Dense(k,activation = 'softmax')(flat)\n",
        "    model = tf.keras.models.Model(inputs = model_input, outputs = out)\n",
        "    return model,model_pretext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQifJaL-YsxA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcbceb42-6cb6-4c07-9f00-6f1e7a44d8fd"
      },
      "source": [
        "model2,model_pretext2 = my_model_pretext()\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics = [\"accuracy\"])\n",
        "print(model_pretext2.summary())\n",
        "print(model2.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 250, 250, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 250, 250, 48)      1344      \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 250, 250, 48)      20784     \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 250, 250, 48)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 125, 125, 48)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 125, 125, 96)      41568     \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 125, 125, 96)      83040     \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 125, 125, 96)      0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 1500000)           0         \n",
            "=================================================================\n",
            "Total params: 146,736\n",
            "Trainable params: 146,736\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 250, 250, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 250, 250, 48)      1344      \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 250, 250, 48)      20784     \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 250, 250, 48)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 125, 125, 48)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 125, 125, 96)      41568     \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 125, 125, 96)      83040     \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 125, 125, 96)      0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 1500000)           0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 4)                 6000004   \n",
            "=================================================================\n",
            "Total params: 6,146,740\n",
            "Trainable params: 6,146,740\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4vPNKLIY3JZ"
      },
      "source": [
        "## Define your callbacks (save your model, patience, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqEs_XyfY5Rf"
      },
      "source": [
        "\n",
        "model_name_pretext = \"best_model_tomato_cnn_rot_pretext.h5\"\n",
        "model_name_pretext_no_top = \"best_model_tomato_cnn_rot_pretext_no_top.h5\"\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 20)\n",
        "\n",
        "monitor = tf.keras.callbacks.ModelCheckpoint(model_name_pretext, monitor='val_loss',\\\n",
        "                                             verbose=0,save_best_only=True,\\\n",
        "                                             save_weights_only=True,\\\n",
        "                                             mode='min')\n",
        "# Learning rate schedule\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch%10 == 0:\n",
        "        lr = lr/2\n",
        "    return lr\n",
        "\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler,verbose = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mV9Bq2yZBer"
      },
      "source": [
        "## Prepare your data to train pretext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de----0Qkx3B"
      },
      "source": [
        "IMG_WIDTH = 250\n",
        "IMG_HEIGHT = 250\n",
        "\n",
        "# functions to resize, normalize and load the image data\n",
        "\n",
        "def resize_image_PIL(image, width, height, channels=3):\n",
        "  return np.resize(image, (height, width, channels))\n",
        "\n",
        "def normalize_image(image):\n",
        "  return image/255 \n",
        "\n",
        "def load_plant_data_PIL(data_dir=\"/content/gdrive/My Drive/Kaggle/PlantVillage/All_Images/AllTomato\", img_width=250, img_height=250):\n",
        "  img_data = []\n",
        "\n",
        "  for file in os.listdir(os.path.join(data_dir)):\n",
        "    image_path = (os.path.join(data_dir, file))\n",
        "    image = np.array(Image.open(image_path))\n",
        "    image = resize_image_PIL(image=image, height=img_height, width=img_width)\n",
        "    image = normalize_image(image)\n",
        "    img_data.append(image)\n",
        "  \n",
        "  return np.asarray(img_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJEZi4CqZFIW"
      },
      "source": [
        "# Preparing dataset\n",
        "\n",
        "# X contains all tomato data for the 4 classes. Both the generalized and original plant village data. \n",
        "X = load_plant_data_PIL(img_width=IMG_WIDTH, img_height=IMG_HEIGHT) \n",
        "\n",
        "X_augmented = np.zeros((X.shape[0]*4,250,250,3))\n",
        "X_augmented[::4] = X\n",
        "\n",
        "# adding rotations to images\n",
        "X_augmented[1::4] = rotate(X, angle = 90, axes = (1,2))\n",
        "X_augmented[2::4] = rotate(X, angle = 180, axes = (1,2))\n",
        "X_augmented[3::4] = rotate(X, angle = 270, axes = (1,2))\n",
        "\n",
        "# one-hot encoding \n",
        "Y_augmented = np.zeros((X.shape[0]*4,4), dtype = int)\n",
        "Y_augmented[::4,0] = 1\n",
        "Y_augmented[1::4,1] = 1\n",
        "Y_augmented[2::4,2] = 1\n",
        "Y_augmented[3::4,3] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtz0WlpYZMGl"
      },
      "source": [
        "## Train your model on pretext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcJmR2VPZPBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee7bea8f-26bf-4a82-d1d4-a947e2bb8f35"
      },
      "source": [
        "model2.fit(X_augmented,Y_augmented, batch_size = 128, epochs = 50, \\\n",
        "          verbose = 1, callbacks= [early_stop, monitor, lr_schedule],validation_split = 0.3, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 58s 2s/step - loss: 1.6489 - accuracy: 0.2512 - val_loss: 1.2185 - val_accuracy: 0.3036\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 10s 1s/step - loss: 1.0624 - accuracy: 0.5308 - val_loss: 0.7588 - val_accuracy: 0.7455\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 10s 1s/step - loss: 0.5116 - accuracy: 0.8856 - val_loss: 0.3784 - val_accuracy: 0.9174\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 10s 1s/step - loss: 0.2332 - accuracy: 0.9221 - val_loss: 0.2354 - val_accuracy: 0.9353\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 10s 1s/step - loss: 0.1499 - accuracy: 0.9462 - val_loss: 0.2489 - val_accuracy: 0.9062\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.1307 - accuracy: 0.9505 - val_loss: 0.2021 - val_accuracy: 0.9375\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0871 - accuracy: 0.9713 - val_loss: 0.2017 - val_accuracy: 0.9353\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0877 - accuracy: 0.9622 - val_loss: 0.1852 - val_accuracy: 0.9375\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0594 - accuracy: 0.9809 - val_loss: 0.1709 - val_accuracy: 0.9397\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0387 - accuracy: 0.9882 - val_loss: 0.1603 - val_accuracy: 0.9442\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0323 - accuracy: 0.9911 - val_loss: 0.1545 - val_accuracy: 0.9487\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0279 - accuracy: 0.9904 - val_loss: 0.1490 - val_accuracy: 0.9531\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0261 - accuracy: 0.9949 - val_loss: 0.1448 - val_accuracy: 0.9531\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0192 - accuracy: 0.9966 - val_loss: 0.1457 - val_accuracy: 0.9531\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0217 - accuracy: 0.9957 - val_loss: 0.1403 - val_accuracy: 0.9554\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.9554\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9554\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0134 - accuracy: 0.9985 - val_loss: 0.1333 - val_accuracy: 0.9554\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9576\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 0.9509\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0107 - accuracy: 0.9977 - val_loss: 0.1287 - val_accuracy: 0.9554\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9554\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9531\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9554\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9554\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 0.9554\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1260 - val_accuracy: 0.9576\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9554\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1247 - val_accuracy: 0.9554\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9554\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1243 - val_accuracy: 0.9554\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9576\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 0.9554\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 0.9554\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9554\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9554\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 0.9554\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9554\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9576\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 0.9554\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 0.9576\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9576\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1219 - val_accuracy: 0.9554\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9554\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9576\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9576\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9576\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9576\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9576\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 11s 1s/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9554\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f61fef5e4d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bamvMV4EJO80"
      },
      "source": [
        "# 5. Downstream task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_46h5KdZVzK"
      },
      "source": [
        "## Train your model on downstream task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YTIhXHxZXpl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "465240f0-8083-4802-deda-54389794031e"
      },
      "source": [
        "model3, model_pretext3 = my_model_pretext(ishape = (250,250,3),k = 4, lr = 1e-6)\n",
        "model3.load_weights(model_name_pretext)\n",
        "model_pretext3.save_weights(model_name_pretext_no_top)\n",
        "\n",
        "model3, model_pretext3 = my_model_pretext(ishape = (250,250,3),k = 4, lr = 1e-6)\n",
        "model_pretext3.load_weights(model_name_pretext_no_top)\n",
        "model_pretext3.trainable = False\n",
        "model3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics = [\"accuracy\"])\n",
        "print(model3.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 250, 250, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 250, 250, 48)      1344      \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 250, 250, 48)      20784     \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 250, 250, 48)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 125, 125, 48)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 125, 125, 96)      41568     \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 125, 125, 96)      83040     \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 125, 125, 96)      0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 1500000)           0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 4)                 6000004   \n",
            "=================================================================\n",
            "Total params: 6,146,740\n",
            "Trainable params: 6,000,004\n",
            "Non-trainable params: 146,736\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiCbAD5TZkW-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6c59cab-489d-4f69-e96b-5e3a2a7d6fd8"
      },
      "source": [
        "\n",
        "model3.fit(train_generator,batch_size = 128, epochs = 50, \\\n",
        "          verbose = 1, callbacks= [early_stop, monitor, lr_schedule],validation_data=val_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "98/98 [==============================] - 1446s 15s/step - loss: 1.3610 - accuracy: 0.4879 - val_loss: 0.6105 - val_accuracy: 0.7878\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 51s 524ms/step - loss: 0.5391 - accuracy: 0.8088 - val_loss: 0.5382 - val_accuracy: 0.7878\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 51s 528ms/step - loss: 0.4117 - accuracy: 0.8557 - val_loss: 0.4286 - val_accuracy: 0.8663\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 52s 526ms/step - loss: 0.3764 - accuracy: 0.8657 - val_loss: 0.3372 - val_accuracy: 0.9244\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 51s 525ms/step - loss: 0.3250 - accuracy: 0.8999 - val_loss: 0.3558 - val_accuracy: 0.8924\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 52s 528ms/step - loss: 0.3405 - accuracy: 0.8764 - val_loss: 0.3067 - val_accuracy: 0.9012\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 52s 526ms/step - loss: 0.3118 - accuracy: 0.8923 - val_loss: 0.3844 - val_accuracy: 0.8634\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 52s 525ms/step - loss: 0.3275 - accuracy: 0.8842 - val_loss: 0.2741 - val_accuracy: 0.9244\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 52s 526ms/step - loss: 0.2282 - accuracy: 0.9268 - val_loss: 0.3817 - val_accuracy: 0.8663\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 51s 525ms/step - loss: 0.2558 - accuracy: 0.9061 - val_loss: 0.2851 - val_accuracy: 0.8953\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6207ecf8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNicvwyGZnI3"
      },
      "source": [
        "model_pretext3.trainable = True\n",
        "model3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics = [\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgWAtX0sZrCV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "ff494123-8dce-4dfa-8dd5-8299b2585247"
      },
      "source": [
        "model3.fit(train_generator,batch_size = 128, epochs = 50, \\\n",
        "          verbose = 1, callbacks= [early_stop, monitor, lr_schedule],validation_data=val_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "98/98 [==============================] - 62s 602ms/step - loss: 0.4838 - accuracy: 0.8394 - val_loss: 0.2037 - val_accuracy: 0.9506\n",
            "Epoch 2/50\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1844 - accuracy: 0.9425"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-7f4fa123f3ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_schedule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1139\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1142\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9Snf4lzZvmg"
      },
      "source": [
        "# 6. Test your model on the test and extract relevant metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9cpalSxZuH2"
      },
      "source": [
        "#using normal test generator \n",
        "model.load_weights(model_name_pretext)\n",
        "metrics = model.evaluate(test_generator) # Get metrics from generators\n",
        "print(\"Categorical cross-entropy:\", metrics[0])\n",
        "print(\"Accuracy:\", metrics[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD99Tqo9i4ax"
      },
      "source": [
        "#using generalized test set data\n",
        "model.load_weights(model_name_pretext)\n",
        "metrics = model.evaluate(general_test_generator)\n",
        "print(\"Categorical cross-entropy:\", metrics[0])\n",
        "print(\"Accuracy:\", metrics[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}