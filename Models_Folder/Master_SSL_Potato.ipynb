{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Master_SSL_Potato.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuGew0mBo6Nm"
      },
      "source": [
        "# Master file Potato - Testing the SSL Approach\n",
        "Our team attempted a self-supervised algorithm for the tomato and potato models in attempt to increase model generalizability. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "659nNMaacXjN"
      },
      "source": [
        "# 1. Load the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6knIUbecKhk",
        "outputId": "d335e7a5-bece-4a8f-fd37-b5e4baa6d878"
      },
      "source": [
        "# download the Kaggle dataset instructions here:\n",
        "# https://medium.com/analytics-vidhya/how-to-fetch-kaggle-datasets-into-google-colab-ea682569851a\n",
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# configure path to Kaggle json file \n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "# /content/gdrive/My Drive/Kaggle is the path where kaggle.json is present in the Google Drive\n",
        "\n",
        "#changing the working directory\n",
        "%cd /content/gdrive/My Drive/Kaggle\n",
        "#Check the present working directory using pwd command\n",
        "\n",
        "#download kaggle dataset\n",
        "# comment out so i dont re-download everytime\n",
        "# !kaggle datasets download -d emmarex/plantdisease\n",
        "\n",
        "#unzip the Plan Village Dataset\n",
        "#unzipping the zip files and deleting the zip files\n",
        "# !unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/.shortcut-targets-by-id/1AE_ah6OZ6tuGxdM5Y8ousz-lKzgRa6TZ/Kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk9sV5g4crD8"
      },
      "source": [
        "# 2. Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KQUs9fMcuE0"
      },
      "source": [
        "import random as random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n",
        "from scipy.ndimage import rotate\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Input\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from  matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.regularizers import l2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL62V98xXjNT"
      },
      "source": [
        "# 3. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnJ1Qwf_Xi73",
        "outputId": "041a436b-6890-450e-8edc-a3c66ca1cf7f"
      },
      "source": [
        "print(os.getcwd())\n",
        "data_dir=r'/content/gdrive/My Drive/Kaggle/PlantVillage_Sorted/'\n",
        "general_data_dir=r'/content/gdrive/My Drive/General_Validation_Datasets/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1AE_ah6OZ6tuGxdM5Y8ousz-lKzgRa6TZ/Kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LZ1yMDvQli6"
      },
      "source": [
        "### Potato Image Data Generator Classes\n",
        "\n",
        "* Potato___Early_blight \n",
        "* Potato___Late_blight \n",
        "* Potato___healthy \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoO4nJmpXV2S",
        "outputId": "053e5986-e153-4c32-e398-b5e7f482f8e2"
      },
      "source": [
        "seed = 909 # (IMPORTANT) to input image and corresponding target with same augmentation parameter.\n",
        "image_size = (250,250)\n",
        "batch = 32\n",
        "# the image hierarchy is important\n",
        "# see: https://stackoverflow.com/questions/49535561/imagedatagenerator-on-a-folder\n",
        "\n",
        "# kaggle --->PlantVillage folder\n",
        "#               |\n",
        "#               Development folder\n",
        "#                   split the total amount of images into 80% development, \n",
        "#                   and this will be further split by dev_params into tran and val generators (in code)\n",
        "#                         |___> all 15 classes exist in this folder with 80% of the total photos\n",
        "#               |\n",
        "#               |\n",
        "#               Test folder\n",
        "#                   split the total amount of images into 20% test\n",
        "#                         |___> all 15 classes exist in this folder with 20% of the total photos\n",
        "\n",
        "# General_Validation_Datasets\n",
        "#               | Contains all classes with data found from general sources\n",
        "\n",
        "\n",
        "# CREATE THE TRAIN/VAL GENERATORS HERE\n",
        "# notice that i split the gen_params into 20% val 80% train \n",
        "dev_params = { \"validation_split\":0.2, \"rescale\":1.0/255,\"featurewise_center\":False,\"samplewise_center\":False,\"featurewise_std_normalization\":False,\\\n",
        "              \"samplewise_std_normalization\":False,\"zca_whitening\":False,\"rotation_range\":20,\"width_shift_range\":0.1,\"height_shift_range\":0.1,\\\n",
        "              \"shear_range\":0.2, \"zoom_range\":0.1,\"horizontal_flip\":True,\"fill_mode\":'constant',\\\n",
        "               \"cval\": 0}\n",
        "\n",
        "train_image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**dev_params) \n",
        "val_image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**dev_params) \n",
        "\n",
        "# use classes tag to only specify a certain class \n",
        "train_generator = train_image_datagen.flow_from_directory(data_dir+'development', subset = 'training', classes = ['Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy' ],\n",
        "                                                     batch_size = batch,seed=seed, target_size=image_size,color_mode='rgb',shuffle = True)\n",
        "val_generator = val_image_datagen.flow_from_directory(data_dir+'development', subset = 'validation', classes = ['Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy'],\n",
        "                                                     batch_size = batch,seed=seed, target_size=image_size,color_mode='rgb',shuffle = True)\n",
        "\n",
        "# CREATE THE TEST GENERATOR HERE\n",
        "test_dir = data_dir+'test' # This is the test folder!!\n",
        "test_params = {\"rescale\":1.0/255,\"featurewise_center\":False,\"samplewise_center\":False,\"featurewise_std_normalization\":False,\\\n",
        "              \"samplewise_std_normalization\":False,\"zca_whitening\":False,\"rotation_range\":20,\"width_shift_range\":0.1,\"height_shift_range\":0.1,\\\n",
        "              \"shear_range\":0.2, \"zoom_range\":0.1,\"horizontal_flip\":True,\"fill_mode\":'constant',\\\n",
        "               \"cval\": 0}\n",
        "test_image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**test_params) \n",
        "# use classes tag to only specify a certain class \n",
        "test_generator = train_image_datagen.flow_from_directory(test_dir, classes = ['Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy'],\n",
        "                                                         batch_size = batch,seed=seed, target_size=image_size,color_mode='rgb',shuffle = True)\n",
        "\n",
        "\n",
        "# CREATE THE GENERAL TEST GENERATOR HERE (testing dataset outside of PlantVillage)\n",
        "test = 'ON' # turning this test case on/off\n",
        "if test is 'ON':\n",
        "  general_test_params = {\"rescale\":1.0/255,\"featurewise_center\":False,\"samplewise_center\":False,\"featurewise_std_normalization\":False,\\\n",
        "                \"samplewise_std_normalization\":False,\"zca_whitening\":False,\"rotation_range\":20,\"width_shift_range\":0.1,\"height_shift_range\":0.1,\\\n",
        "                \"shear_range\":0.2, \"zoom_range\":0.1,\"horizontal_flip\":True,\"fill_mode\":'constant',\\\n",
        "                \"cval\": 0}\n",
        "\n",
        "  general_test_image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**test_params) \n",
        "\n",
        "  # use classes tag to only specify a certain class \n",
        "  general_test_generator = train_image_datagen.flow_from_directory(general_data_dir, classes = ['Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy'],\n",
        "                                                          batch_size = batch,seed=seed, target_size=image_size,color_mode='rgb',shuffle = True)\n",
        "else:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1377 images belonging to 3 classes.\n",
            "Found 344 images belonging to 3 classes.\n",
            "Found 431 images belonging to 3 classes.\n",
            "Found 31 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7p7KOJBItv3"
      },
      "source": [
        "### Exploring the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhvwwLNMEGYT",
        "outputId": "aba54720-1de0-4c07-a689-d5c7325adc80"
      },
      "source": [
        "# I want to see the labels, lets access the keys in the dictionary\n",
        "# https://stackoverflow.com/questions/48373685/keras-imagedatagenerator-how-to-get-all-labels-from-data\n",
        "# train_generator.class_indices.keys()\n",
        "# train_generator.class_indices.values()\n",
        "\n",
        "for key, val in train_generator.class_indices.items(): # see the classes\n",
        "  print(key, val)\n",
        "\n",
        "# heres the labels, are they one hot encoded? No, and they dont have to be see Q's above\n",
        "x= train_generator.next()\n",
        "train_generator.labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Potato___Early_blight 0\n",
            "Potato___Late_blight 1\n",
            "Potato___healthy 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 2, 2, 2], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr3yiJfbR2Lc"
      },
      "source": [
        "# 4. SSL Pre-Text\n",
        "Defining and training a model on a pretext task (i.e., image rotation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rhuOU3dYm2g"
      },
      "source": [
        "## Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c28AtzURzzl"
      },
      "source": [
        "def my_model_pretext(ishape = (250,250,3), k = 4, lr = 1e-4):\n",
        "    model_input = tf.keras.layers.Input(shape = ishape)\n",
        "    l1 = tf.keras.layers.Conv2D(48, (3,3), padding='same', activation='relu')(model_input)\n",
        "    l2 = tf.keras.layers.Conv2D(48, (3,3), padding='same', activation='relu')(l1)\n",
        "    l2_drop = tf.keras.layers.Dropout(0.25)(l2)\n",
        "    l3 = tf.keras.layers.MaxPool2D((2,2))(l2_drop)\n",
        "    l4 = tf.keras.layers.Conv2D(96, (3,3), padding='same', activation='relu')(l3)\n",
        "    l5 = tf.keras.layers.Conv2D(96, (3,3), padding='same', activation='relu')(l4)\n",
        "    l5_drop = tf.keras.layers.Dropout(0.25)(l5)\n",
        "    flat = tf.keras.layers.Flatten()(l5_drop)\n",
        "    model_pretext = tf.keras.models.Model(inputs = model_input, outputs = flat)\n",
        "    out = tf.keras.layers.Dense(k,activation = 'softmax')(flat)\n",
        "    model = tf.keras.models.Model(inputs = model_input, outputs = out)\n",
        "    return model,model_pretext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQifJaL-YsxA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f7d79ab-4b61-488e-aa97-53475b961334"
      },
      "source": [
        "model2,model_pretext2 = my_model_pretext()\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics = [\"accuracy\"])\n",
        "print(model_pretext2.summary())\n",
        "print(model2.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 250, 250, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 250, 250, 48)      1344      \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 250, 250, 48)      20784     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 250, 250, 48)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 125, 125, 48)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 125, 125, 96)      41568     \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 125, 125, 96)      83040     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 125, 125, 96)      0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1500000)           0         \n",
            "=================================================================\n",
            "Total params: 146,736\n",
            "Trainable params: 146,736\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 250, 250, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 250, 250, 48)      1344      \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 250, 250, 48)      20784     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 250, 250, 48)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 125, 125, 48)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 125, 125, 96)      41568     \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 125, 125, 96)      83040     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 125, 125, 96)      0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1500000)           0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4)                 6000004   \n",
            "=================================================================\n",
            "Total params: 6,146,740\n",
            "Trainable params: 6,146,740\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4vPNKLIY3JZ"
      },
      "source": [
        "## Define your callbacks (save your model, patience, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqEs_XyfY5Rf"
      },
      "source": [
        "\n",
        "model_name_pretext = \"best_model_potato_cnn_rot_pretext.h5\"\n",
        "model_name_pretext_no_top = \"best_model_potato_cnn_rot_pretext_no_top.h5\"\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 20)\n",
        "\n",
        "monitor = tf.keras.callbacks.ModelCheckpoint(model_name_pretext, monitor='val_loss',\\\n",
        "                                             verbose=0,save_best_only=True,\\\n",
        "                                             save_weights_only=True,\\\n",
        "                                             mode='min')\n",
        "# Learning rate schedule\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch%10 == 0:\n",
        "        lr = lr/2\n",
        "    return lr\n",
        "\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler,verbose = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mV9Bq2yZBer"
      },
      "source": [
        "## Prepare your data to train pretext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de----0Qkx3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "427a9685-1bbe-406e-de7e-20aebef0826a"
      },
      "source": [
        "IMG_WIDTH = 250\n",
        "IMG_HEIGHT = 250\n",
        "\n",
        "#functions to resize, normalize and load the image data\n",
        "\n",
        "def resize_image_PIL(image, width, height, channels=3):\n",
        "  return np.resize(image, (height, width, channels))\n",
        "\n",
        "def normalize_image(image):\n",
        "  return image/255 \n",
        "\n",
        "# #changing the working directory\n",
        "# %cd /content/gdrive/My Drive/Kaggle\n",
        "!ls \n",
        "\n",
        "def load_plant_data_PIL(data_dir=r'All_Images/AllPotato', img_width=250, img_height=250):\n",
        "  img_data = []\n",
        "\n",
        "  for file in os.listdir(os.path.join(data_dir)):\n",
        "    image_path = (os.path.join(data_dir, file))\n",
        "    image = np.array(Image.open(image_path))\n",
        "    image = resize_image_PIL(image=image, height=img_height, width=img_width)\n",
        "    image = normalize_image(image)\n",
        "    img_data.append(image)\n",
        "  \n",
        "  return np.asarray(img_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All_Images\t\t\t\t     kaggle.json   PlantVillage_Sorted\n",
            "best_model_tomato_cnn_rot_pretext.h5\t     logs\t   test_model.h5\n",
            "best_model_tomato_cnn_rot_pretext_no_top.h5  PlantVillage  tomato_model.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Coq2PkmBIqpo"
      },
      "source": [
        "# Preparing dataset\n",
        "\n",
        "# X contains all potato data for the 3 classes. Both the generalized and original plant village data. \n",
        "X = load_plant_data_PIL(img_width=IMG_WIDTH, img_height=IMG_HEIGHT) \n",
        "\n",
        "X_augmented = np.zeros((X.shape[0]*4,250,250,3))\n",
        "X_augmented[::4] = X\n",
        "\n",
        "# adding rotations to images\n",
        "X_augmented[1::4] = rotate(X, angle = 90, axes = (1,2))\n",
        "X_augmented[2::4] = rotate(X, angle = 180, axes = (1,2))\n",
        "X_augmented[3::4] = rotate(X, angle = 270, axes = (1,2))\n",
        "\n",
        "# one-hot encoding\n",
        "Y_augmented = np.zeros((X.shape[0]*4,4), dtype = int)\n",
        "Y_augmented[::4,0] = 1\n",
        "Y_augmented[1::4,1] = 1\n",
        "Y_augmented[2::4,2] = 1\n",
        "Y_augmented[3::4,3] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtz0WlpYZMGl"
      },
      "source": [
        "## Train your model on pretext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcJmR2VPZPBf"
      },
      "source": [
        "model2.fit(X_augmented,Y_augmented, batch_size = 128, epochs = 50, \\\n",
        "          verbose = 1, callbacks= [early_stop, monitor, lr_schedule],validation_split = 0.3, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhq8BkxMJJgX"
      },
      "source": [
        "# 5. Downstream task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_46h5KdZVzK"
      },
      "source": [
        "## Train your model on downstream task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YTIhXHxZXpl"
      },
      "source": [
        "model3, model_pretext3 = my_model_pretext(ishape = (250,250,3),k = 4, lr = 1e-6)\n",
        "model3.load_weights(model_name_pretext)\n",
        "model_pretext3.save_weights(model_name_pretext_no_top)\n",
        "\n",
        "model3, model_pretext3 = my_model_pretext(ishape = (250,250,3),k = 3, lr = 1e-6) # K = 3 because 3 potato classes\n",
        "model_pretext3.load_weights(model_name_pretext_no_top)\n",
        "model_pretext3.trainable = False\n",
        "model3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics = [\"accuracy\"])\n",
        "print(model3.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiCbAD5TZkW-"
      },
      "source": [
        "\n",
        "model3.fit(train_generator,batch_size = 128, epochs = 50, \\\n",
        "          verbose = 1, callbacks= [early_stop, monitor, lr_schedule],validation_data=val_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNicvwyGZnI3"
      },
      "source": [
        "model_pretext3.trainable = True\n",
        "model3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics = [\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgWAtX0sZrCV"
      },
      "source": [
        "model3.fit(train_generator,batch_size = 128, epochs = 50, \\\n",
        "          verbose = 1, callbacks= [early_stop, monitor, lr_schedule],validation_data=val_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9Snf4lzZvmg"
      },
      "source": [
        "# 6. Test your model on the test and extract relevant metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9cpalSxZuH2"
      },
      "source": [
        "#using normal test generator \n",
        "model.load_weights(model_name_pretext)\n",
        "metrics = model.evaluate(test_generator) # Get metrics from generators\n",
        "print(\"Categorical cross-entropy:\", metrics[0])\n",
        "print(\"Accuracy:\", metrics[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD99Tqo9i4ax"
      },
      "source": [
        "#using generalized test set data\n",
        "model.load_weights(model_name_pretext)\n",
        "metrics = model.evaluate(general_test_generator)\n",
        "print(\"Categorical cross-entropy:\", metrics[0])\n",
        "print(\"Accuracy:\", metrics[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}